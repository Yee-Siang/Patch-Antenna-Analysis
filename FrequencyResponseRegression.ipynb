{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FrequencyResponseRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0g0whB89wqx",
        "outputId": "b8722ca9-5e1e-49bb-a424-7d4fd196f6b0"
      },
      "source": [
        "!gdown --id '1F_eh3qALZh40Gx8Zaej4oJqPZ-IIEN-V' --output network.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1F_eh3qALZh40Gx8Zaej4oJqPZ-IIEN-V\n",
            "To: /content/network.csv\n",
            "\r  0% 0.00/61.7k [00:00<?, ?B/s]\r100% 61.7k/61.7k [00:00<00:00, 4.00MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-JIC1fG_n6w"
      },
      "source": [
        "tr_path = 'network.csv'  # path to training data\n",
        "tt_path = 'network.csv'   # path to testing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k25Xvw8Z-2HX"
      },
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "myseed = 42069  # set a random seed for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyPXv97v-_h9"
      },
      "source": [
        "def get_device():\n",
        "    ''' Get device (if GPU is available, use GPU) '''\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def plot_learning_curve(loss_record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    total_steps = len(loss_record['train'])\n",
        "    x_1 = range(total_steps)\n",
        "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
        "    plt.ylim(0.0, 0.01)\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('MSE loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "    ''' Plot prediction of your DNN '''\n",
        "    if preds is None or targets is None:\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        for x, y in dv_set:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                preds.append(pred.detach().cpu())\n",
        "                targets.append(y.detach().cpu())\n",
        "        preds = torch.cat(preds, dim=0).numpy()\n",
        "        targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "    figure()\n",
        "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "    plt.xlim(-0.2, lim)\n",
        "    plt.ylim(-0.2, lim)\n",
        "    plt.xlabel('ground truth value')\n",
        "    plt.ylabel('predicted value')\n",
        "    plt.title('Ground Truth v.s. Prediction')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zci4kXut_Tqe"
      },
      "source": [
        "class AntennaNetwork(Dataset):\n",
        "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
        "    def __init__(self,\n",
        "                 path,\n",
        "                 mode='train',\n",
        "                 target_only=False):\n",
        "        self.mode = mode\n",
        "\n",
        "        # Read data into numpy arrays\n",
        "        with open(path, 'r') as fp:\n",
        "            data = list(csv.reader(fp))\n",
        "            data = np.array(data[3:])[:, 0:].astype(float)\n",
        "            \n",
        "        \n",
        "        if not target_only:\n",
        "            feats = list(range(5))\n",
        "        else:\n",
        "            feats = np.array([0, 1, 2])\n",
        "\n",
        "        if mode == 'test':\n",
        "           \n",
        "            data = data[:, feats]\n",
        "            \n",
        "            self.data = torch.FloatTensor(data)\n",
        "        else:\n",
        "            \n",
        "            target = data[:, 1]\n",
        "            data = data[:, feats]\n",
        "            # Splitting training data into train & dev sets\n",
        "            if mode == 'train':\n",
        "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
        "            elif mode == 'dev':\n",
        "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
        "            \n",
        "            # Convert data into PyTorch tensors\n",
        "            self.data = torch.FloatTensor(data[indices])\n",
        "            self.target = torch.FloatTensor(target[indices])\n",
        "\n",
        "        self.data[:, 0:] = \\\n",
        "            (self.data[:, 0:] - self.data[:, 0:].mean(dim=0, keepdim=True)) \\\n",
        "            / self.data[:, 0:].std(dim=0, keepdim=True)\n",
        "\n",
        "        self.dim = self.data.shape[1]\n",
        "\n",
        "        print('Finished reading the {} set of Antenna Dataset ({} samples found, each dim = {})'\n",
        "              .format(mode, len(self.data), self.dim))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Returns one sample at a time\n",
        "        if self.mode in ['train', 'dev']:\n",
        "            # For training\n",
        "            return self.data[index], self.target[index]\n",
        "        else:\n",
        "            # For testing (no target)\n",
        "            return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns the size of the dataset\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI7oKab4A4Vq"
      },
      "source": [
        "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
        "    ''' Generates a dataset, then is put into a dataloader. '''\n",
        "    dataset = AntennaNetwork(path, mode=mode, target_only=target_only)  # Construct dataset\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dnZw_MBA4lh"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        # TODO: How to modify this model to achieve better performance?\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 90),\n",
        "            nn.RReLU(),\n",
        "            nn.Linear(90, 1)\n",
        "        )\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target):\n",
        "        ''' Calculate loss '''\n",
        "        # TODO: you may implement L1/L2 regularization here\n",
        "        return self.criterion(pred, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rflqxfSsA41C"
      },
      "source": [
        "def train(tr_set, dv_set, model, config, device):\n",
        "    ''' DNN training '''\n",
        "\n",
        "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "\n",
        "    # Setup optimizer\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
        "        model.parameters(), **config['optim_hparas'])\n",
        "\n",
        "    min_mse = 1000000.\n",
        "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "    while epoch < n_epochs:\n",
        "        model.train()                           # set model to training mode\n",
        "        for x, y in tr_set:                     # iterate through the dataloader\n",
        "            optimizer.zero_grad()               # set gradient to zero\n",
        "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
        "            optimizer.step()                    # update model with optimizer\n",
        "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
        "\n",
        "        # After each epoch, test your model on the validation (development) set.\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "        if dev_mse < min_mse:\n",
        "            # Save model if your model improved\n",
        "            min_mse = dev_mse\n",
        "            print('Saving model (epoch = {:4d}, loss = {:.6f})'\n",
        "                .format(epoch + 1, min_mse))\n",
        "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "\n",
        "        epoch += 1\n",
        "        loss_record['dev'].append(dev_mse)\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "    return min_mse, loss_record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USPMEfFPA5Cw"
      },
      "source": [
        "def dev(dv_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    total_loss = 0\n",
        "    for x, y in dv_set:                         # iterate through the dataloader\n",
        "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
        "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7daC-B4Bawa"
      },
      "source": [
        "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
        "target_only = True                 \n",
        "\n",
        "config = {\n",
        "    'n_epochs': 3000,                # maximum number of epochs\n",
        "    'batch_size': 20,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.0001,                 # learning rate of SGD\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot8Mh0RJBffl",
        "outputId": "9d015398-8405-4b77-d560-a7a3dd7eaf51"
      },
      "source": [
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished reading the train set of COVID19 Dataset (900 samples found, each dim = 3)\n",
            "Finished reading the dev set of COVID19 Dataset (101 samples found, each dim = 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejwVDawpB1u5"
      },
      "source": [
        "model = NeuralNet(tr_set.dataset.dim).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXZtQd7vB1-o",
        "outputId": "63b9b307-edd0-4920-93e4-e8ce8b0dbf37"
      },
      "source": [
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model (epoch =    1, loss = 3.465147)\n",
            "Saving model (epoch =    2, loss = 1.002585)\n",
            "Saving model (epoch =    3, loss = 0.537482)\n",
            "Saving model (epoch =    4, loss = 0.330349)\n",
            "Saving model (epoch =    5, loss = 0.222101)\n",
            "Saving model (epoch =    6, loss = 0.155861)\n",
            "Saving model (epoch =    7, loss = 0.118753)\n",
            "Saving model (epoch =    8, loss = 0.097389)\n",
            "Saving model (epoch =    9, loss = 0.082993)\n",
            "Saving model (epoch =   10, loss = 0.073987)\n",
            "Saving model (epoch =   11, loss = 0.067110)\n",
            "Saving model (epoch =   12, loss = 0.061668)\n",
            "Saving model (epoch =   13, loss = 0.057564)\n",
            "Saving model (epoch =   14, loss = 0.053483)\n",
            "Saving model (epoch =   15, loss = 0.050085)\n",
            "Saving model (epoch =   16, loss = 0.047093)\n",
            "Saving model (epoch =   17, loss = 0.044171)\n",
            "Saving model (epoch =   18, loss = 0.041517)\n",
            "Saving model (epoch =   19, loss = 0.039196)\n",
            "Saving model (epoch =   20, loss = 0.036884)\n",
            "Saving model (epoch =   21, loss = 0.034933)\n",
            "Saving model (epoch =   22, loss = 0.032867)\n",
            "Saving model (epoch =   23, loss = 0.031103)\n",
            "Saving model (epoch =   24, loss = 0.029352)\n",
            "Saving model (epoch =   25, loss = 0.027734)\n",
            "Saving model (epoch =   26, loss = 0.026315)\n",
            "Saving model (epoch =   27, loss = 0.024905)\n",
            "Saving model (epoch =   28, loss = 0.023740)\n",
            "Saving model (epoch =   29, loss = 0.022514)\n",
            "Saving model (epoch =   30, loss = 0.021336)\n",
            "Saving model (epoch =   31, loss = 0.020264)\n",
            "Saving model (epoch =   32, loss = 0.019401)\n",
            "Saving model (epoch =   33, loss = 0.018391)\n",
            "Saving model (epoch =   34, loss = 0.017537)\n",
            "Saving model (epoch =   35, loss = 0.016683)\n",
            "Saving model (epoch =   36, loss = 0.015881)\n",
            "Saving model (epoch =   37, loss = 0.015311)\n",
            "Saving model (epoch =   38, loss = 0.014598)\n",
            "Saving model (epoch =   39, loss = 0.014048)\n",
            "Saving model (epoch =   40, loss = 0.013382)\n",
            "Saving model (epoch =   41, loss = 0.013016)\n",
            "Saving model (epoch =   42, loss = 0.012481)\n",
            "Saving model (epoch =   43, loss = 0.011957)\n",
            "Saving model (epoch =   44, loss = 0.011552)\n",
            "Saving model (epoch =   45, loss = 0.011088)\n",
            "Saving model (epoch =   46, loss = 0.010758)\n",
            "Saving model (epoch =   47, loss = 0.010378)\n",
            "Saving model (epoch =   48, loss = 0.010043)\n",
            "Saving model (epoch =   49, loss = 0.009753)\n",
            "Saving model (epoch =   50, loss = 0.009467)\n",
            "Saving model (epoch =   51, loss = 0.009206)\n",
            "Saving model (epoch =   52, loss = 0.008904)\n",
            "Saving model (epoch =   53, loss = 0.008648)\n",
            "Saving model (epoch =   54, loss = 0.008391)\n",
            "Saving model (epoch =   55, loss = 0.008136)\n",
            "Saving model (epoch =   56, loss = 0.007956)\n",
            "Saving model (epoch =   57, loss = 0.007806)\n",
            "Saving model (epoch =   58, loss = 0.007648)\n",
            "Saving model (epoch =   59, loss = 0.007507)\n",
            "Saving model (epoch =   60, loss = 0.007359)\n",
            "Saving model (epoch =   61, loss = 0.007174)\n",
            "Saving model (epoch =   62, loss = 0.007093)\n",
            "Saving model (epoch =   63, loss = 0.006977)\n",
            "Saving model (epoch =   64, loss = 0.006790)\n",
            "Saving model (epoch =   65, loss = 0.006579)\n",
            "Saving model (epoch =   66, loss = 0.006416)\n",
            "Saving model (epoch =   67, loss = 0.006356)\n",
            "Saving model (epoch =   68, loss = 0.006209)\n",
            "Saving model (epoch =   70, loss = 0.006139)\n",
            "Saving model (epoch =   71, loss = 0.006031)\n",
            "Saving model (epoch =   72, loss = 0.005891)\n",
            "Saving model (epoch =   73, loss = 0.005731)\n",
            "Saving model (epoch =   74, loss = 0.005660)\n",
            "Saving model (epoch =   75, loss = 0.005611)\n",
            "Saving model (epoch =   76, loss = 0.005602)\n",
            "Saving model (epoch =   77, loss = 0.005478)\n",
            "Saving model (epoch =   78, loss = 0.005410)\n",
            "Saving model (epoch =   79, loss = 0.005372)\n",
            "Saving model (epoch =   80, loss = 0.005247)\n",
            "Saving model (epoch =   81, loss = 0.005205)\n",
            "Saving model (epoch =   82, loss = 0.005135)\n",
            "Saving model (epoch =   83, loss = 0.005028)\n",
            "Saving model (epoch =   84, loss = 0.005026)\n",
            "Saving model (epoch =   85, loss = 0.004951)\n",
            "Saving model (epoch =   86, loss = 0.004893)\n",
            "Saving model (epoch =   87, loss = 0.004848)\n",
            "Saving model (epoch =   88, loss = 0.004822)\n",
            "Saving model (epoch =   89, loss = 0.004806)\n",
            "Saving model (epoch =   90, loss = 0.004711)\n",
            "Saving model (epoch =   91, loss = 0.004674)\n",
            "Saving model (epoch =   93, loss = 0.004567)\n",
            "Saving model (epoch =   94, loss = 0.004563)\n",
            "Saving model (epoch =   95, loss = 0.004499)\n",
            "Saving model (epoch =   96, loss = 0.004425)\n",
            "Saving model (epoch =   97, loss = 0.004376)\n",
            "Saving model (epoch =   99, loss = 0.004355)\n",
            "Saving model (epoch =  100, loss = 0.004333)\n",
            "Saving model (epoch =  101, loss = 0.004287)\n",
            "Saving model (epoch =  102, loss = 0.004235)\n",
            "Saving model (epoch =  103, loss = 0.004201)\n",
            "Saving model (epoch =  104, loss = 0.004131)\n",
            "Saving model (epoch =  107, loss = 0.004106)\n",
            "Saving model (epoch =  108, loss = 0.004040)\n",
            "Saving model (epoch =  110, loss = 0.004026)\n",
            "Saving model (epoch =  111, loss = 0.003946)\n",
            "Saving model (epoch =  112, loss = 0.003915)\n",
            "Saving model (epoch =  115, loss = 0.003863)\n",
            "Saving model (epoch =  116, loss = 0.003830)\n",
            "Saving model (epoch =  117, loss = 0.003769)\n",
            "Saving model (epoch =  120, loss = 0.003763)\n",
            "Saving model (epoch =  121, loss = 0.003727)\n",
            "Saving model (epoch =  122, loss = 0.003711)\n",
            "Saving model (epoch =  123, loss = 0.003672)\n",
            "Saving model (epoch =  124, loss = 0.003627)\n",
            "Saving model (epoch =  125, loss = 0.003594)\n",
            "Saving model (epoch =  127, loss = 0.003564)\n",
            "Saving model (epoch =  128, loss = 0.003519)\n",
            "Saving model (epoch =  129, loss = 0.003480)\n",
            "Saving model (epoch =  130, loss = 0.003476)\n",
            "Saving model (epoch =  131, loss = 0.003449)\n",
            "Saving model (epoch =  132, loss = 0.003439)\n",
            "Saving model (epoch =  134, loss = 0.003422)\n",
            "Saving model (epoch =  135, loss = 0.003389)\n",
            "Saving model (epoch =  136, loss = 0.003383)\n",
            "Saving model (epoch =  137, loss = 0.003379)\n",
            "Saving model (epoch =  138, loss = 0.003304)\n",
            "Saving model (epoch =  139, loss = 0.003238)\n",
            "Saving model (epoch =  142, loss = 0.003178)\n",
            "Saving model (epoch =  143, loss = 0.003173)\n",
            "Saving model (epoch =  147, loss = 0.003156)\n",
            "Saving model (epoch =  148, loss = 0.003105)\n",
            "Saving model (epoch =  152, loss = 0.003028)\n",
            "Saving model (epoch =  154, loss = 0.003026)\n",
            "Saving model (epoch =  155, loss = 0.003018)\n",
            "Saving model (epoch =  156, loss = 0.002955)\n",
            "Saving model (epoch =  157, loss = 0.002912)\n",
            "Saving model (epoch =  159, loss = 0.002845)\n",
            "Saving model (epoch =  160, loss = 0.002844)\n",
            "Saving model (epoch =  167, loss = 0.002835)\n",
            "Saving model (epoch =  168, loss = 0.002781)\n",
            "Saving model (epoch =  169, loss = 0.002773)\n",
            "Saving model (epoch =  170, loss = 0.002668)\n",
            "Saving model (epoch =  173, loss = 0.002655)\n",
            "Saving model (epoch =  174, loss = 0.002630)\n",
            "Saving model (epoch =  175, loss = 0.002595)\n",
            "Saving model (epoch =  177, loss = 0.002590)\n",
            "Saving model (epoch =  181, loss = 0.002578)\n",
            "Saving model (epoch =  182, loss = 0.002571)\n",
            "Saving model (epoch =  183, loss = 0.002558)\n",
            "Saving model (epoch =  184, loss = 0.002510)\n",
            "Saving model (epoch =  185, loss = 0.002489)\n",
            "Saving model (epoch =  186, loss = 0.002474)\n",
            "Saving model (epoch =  187, loss = 0.002445)\n",
            "Saving model (epoch =  188, loss = 0.002434)\n",
            "Saving model (epoch =  189, loss = 0.002431)\n",
            "Saving model (epoch =  190, loss = 0.002429)\n",
            "Saving model (epoch =  191, loss = 0.002408)\n",
            "Saving model (epoch =  192, loss = 0.002392)\n",
            "Saving model (epoch =  193, loss = 0.002347)\n",
            "Saving model (epoch =  194, loss = 0.002308)\n",
            "Saving model (epoch =  195, loss = 0.002304)\n",
            "Saving model (epoch =  202, loss = 0.002304)\n",
            "Saving model (epoch =  203, loss = 0.002275)\n",
            "Saving model (epoch =  204, loss = 0.002234)\n",
            "Saving model (epoch =  205, loss = 0.002219)\n",
            "Saving model (epoch =  206, loss = 0.002212)\n",
            "Saving model (epoch =  212, loss = 0.002142)\n",
            "Saving model (epoch =  214, loss = 0.002071)\n",
            "Saving model (epoch =  222, loss = 0.002035)\n",
            "Saving model (epoch =  225, loss = 0.002026)\n",
            "Saving model (epoch =  231, loss = 0.001986)\n",
            "Saving model (epoch =  232, loss = 0.001961)\n",
            "Saving model (epoch =  235, loss = 0.001950)\n",
            "Saving model (epoch =  236, loss = 0.001928)\n",
            "Saving model (epoch =  237, loss = 0.001927)\n",
            "Saving model (epoch =  238, loss = 0.001901)\n",
            "Saving model (epoch =  239, loss = 0.001850)\n",
            "Saving model (epoch =  244, loss = 0.001838)\n",
            "Saving model (epoch =  247, loss = 0.001830)\n",
            "Saving model (epoch =  249, loss = 0.001795)\n",
            "Saving model (epoch =  250, loss = 0.001788)\n",
            "Saving model (epoch =  251, loss = 0.001762)\n",
            "Saving model (epoch =  255, loss = 0.001746)\n",
            "Saving model (epoch =  256, loss = 0.001743)\n",
            "Saving model (epoch =  257, loss = 0.001726)\n",
            "Saving model (epoch =  258, loss = 0.001720)\n",
            "Saving model (epoch =  264, loss = 0.001715)\n",
            "Saving model (epoch =  265, loss = 0.001675)\n",
            "Saving model (epoch =  266, loss = 0.001664)\n",
            "Saving model (epoch =  269, loss = 0.001631)\n",
            "Saving model (epoch =  273, loss = 0.001614)\n",
            "Saving model (epoch =  276, loss = 0.001596)\n",
            "Saving model (epoch =  278, loss = 0.001579)\n",
            "Saving model (epoch =  279, loss = 0.001564)\n",
            "Saving model (epoch =  281, loss = 0.001552)\n",
            "Saving model (epoch =  285, loss = 0.001527)\n",
            "Saving model (epoch =  286, loss = 0.001520)\n",
            "Saving model (epoch =  291, loss = 0.001500)\n",
            "Saving model (epoch =  295, loss = 0.001475)\n",
            "Saving model (epoch =  298, loss = 0.001451)\n",
            "Saving model (epoch =  301, loss = 0.001411)\n",
            "Saving model (epoch =  304, loss = 0.001405)\n",
            "Saving model (epoch =  305, loss = 0.001400)\n",
            "Saving model (epoch =  310, loss = 0.001397)\n",
            "Saving model (epoch =  319, loss = 0.001383)\n",
            "Saving model (epoch =  321, loss = 0.001376)\n",
            "Saving model (epoch =  324, loss = 0.001364)\n",
            "Saving model (epoch =  333, loss = 0.001333)\n",
            "Saving model (epoch =  334, loss = 0.001331)\n",
            "Saving model (epoch =  335, loss = 0.001281)\n",
            "Saving model (epoch =  336, loss = 0.001258)\n",
            "Saving model (epoch =  337, loss = 0.001192)\n",
            "Saving model (epoch =  346, loss = 0.001185)\n",
            "Saving model (epoch =  356, loss = 0.001185)\n",
            "Saving model (epoch =  358, loss = 0.001175)\n",
            "Saving model (epoch =  359, loss = 0.001160)\n",
            "Saving model (epoch =  369, loss = 0.001142)\n",
            "Saving model (epoch =  379, loss = 0.001128)\n",
            "Saving model (epoch =  380, loss = 0.001123)\n",
            "Saving model (epoch =  382, loss = 0.001087)\n",
            "Saving model (epoch =  383, loss = 0.001058)\n",
            "Saving model (epoch =  411, loss = 0.001056)\n",
            "Saving model (epoch =  412, loss = 0.000985)\n",
            "Saving model (epoch =  426, loss = 0.000976)\n",
            "Saving model (epoch =  427, loss = 0.000969)\n",
            "Saving model (epoch =  437, loss = 0.000926)\n",
            "Saving model (epoch =  451, loss = 0.000900)\n",
            "Saving model (epoch =  452, loss = 0.000900)\n",
            "Saving model (epoch =  477, loss = 0.000889)\n",
            "Saving model (epoch =  479, loss = 0.000875)\n",
            "Saving model (epoch =  480, loss = 0.000846)\n",
            "Saving model (epoch =  493, loss = 0.000846)\n",
            "Saving model (epoch =  509, loss = 0.000833)\n",
            "Saving model (epoch =  518, loss = 0.000795)\n",
            "Saving model (epoch =  537, loss = 0.000771)\n",
            "Saving model (epoch =  538, loss = 0.000766)\n",
            "Saving model (epoch =  549, loss = 0.000760)\n",
            "Saving model (epoch =  550, loss = 0.000751)\n",
            "Saving model (epoch =  595, loss = 0.000735)\n",
            "Saving model (epoch =  609, loss = 0.000699)\n",
            "Saving model (epoch =  632, loss = 0.000695)\n",
            "Saving model (epoch =  649, loss = 0.000676)\n",
            "Saving model (epoch =  650, loss = 0.000670)\n",
            "Saving model (epoch =  679, loss = 0.000664)\n",
            "Saving model (epoch =  702, loss = 0.000656)\n",
            "Saving model (epoch =  703, loss = 0.000654)\n",
            "Saving model (epoch =  711, loss = 0.000645)\n",
            "Saving model (epoch =  713, loss = 0.000617)\n",
            "Saving model (epoch =  739, loss = 0.000613)\n",
            "Saving model (epoch =  775, loss = 0.000612)\n",
            "Saving model (epoch =  786, loss = 0.000602)\n",
            "Saving model (epoch =  812, loss = 0.000585)\n",
            "Saving model (epoch =  840, loss = 0.000583)\n",
            "Saving model (epoch =  897, loss = 0.000557)\n",
            "Saving model (epoch =  921, loss = 0.000554)\n",
            "Saving model (epoch =  926, loss = 0.000539)\n",
            "Saving model (epoch =  927, loss = 0.000531)\n",
            "Saving model (epoch =  972, loss = 0.000511)\n",
            "Saving model (epoch = 1077, loss = 0.000511)\n",
            "Saving model (epoch = 1078, loss = 0.000505)\n",
            "Saving model (epoch = 1083, loss = 0.000484)\n",
            "Finished training after 1284 epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sjg1-15JB2MX",
        "outputId": "2ec15f9a-58c9-4a56-e11c-6a5aa0169178"
      },
      "source": [
        "plot_learning_curve(model_loss_record, title='deep model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8gTZLerNFnh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wymUiKs2CuPg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}